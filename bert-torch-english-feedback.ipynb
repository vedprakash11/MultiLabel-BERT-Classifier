{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-28T20:19:43.414305Z","iopub.execute_input":"2022-10-28T20:19:43.415567Z","iopub.status.idle":"2022-10-28T20:19:43.425802Z","shell.execute_reply.started":"2022-10-28T20:19:43.415512Z","shell.execute_reply":"2022-10-28T20:19:43.424747Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n/kaggle/input/feedback-prize-english-language-learning/train.csv\n/kaggle/input/feedback-prize-english-language-learning/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:43.427970Z","iopub.execute_input":"2022-10-28T20:19:43.428723Z","iopub.status.idle":"2022-10-28T20:19:53.061016Z","shell.execute_reply.started":"2022-10-28T20:19:43.428686Z","shell.execute_reply":"2022-10-28T20:19:53.059727Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport shutil\nimport sys\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.064783Z","iopub.execute_input":"2022-10-28T20:19:53.065105Z","iopub.status.idle":"2022-10-28T20:19:53.070873Z","shell.execute_reply.started":"2022-10-28T20:19:53.065070Z","shell.execute_reply":"2022-10-28T20:19:53.069853Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"train_path=\"../input/feedback-prize-english-language-learning/train.csv\"\ntest_path=\"../input/feedback-prize-english-language-learning/test.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.073738Z","iopub.execute_input":"2022-10-28T20:19:53.074426Z","iopub.status.idle":"2022-10-28T20:19:53.082145Z","shell.execute_reply.started":"2022-10-28T20:19:53.074391Z","shell.execute_reply":"2022-10-28T20:19:53.081236Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv(train_path)\ntest_df=pd.read_csv(test_path)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.083805Z","iopub.execute_input":"2022-10-28T20:19:53.084550Z","iopub.status.idle":"2022-10-28T20:19:53.200218Z","shell.execute_reply.started":"2022-10-28T20:19:53.084515Z","shell.execute_reply":"2022-10-28T20:19:53.198159Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  cohesion  \\\n0  0016926B079C  I think that students would benefit from learn...       3.5   \n1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n3  003885A45F42  The best time in life is when you become yours...       4.5   \n4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n\n   syntax  vocabulary  phraseology  grammar  conventions  \n0     3.5         3.0          3.0      4.0          3.0  \n1     2.5         3.0          2.0      2.0          2.5  \n2     3.5         3.0          3.0      3.0          2.5  \n3     4.5         4.5          4.5      4.0          5.0  \n4     3.0         3.0          3.0      2.5          2.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.201644Z","iopub.execute_input":"2022-10-28T20:19:53.202101Z","iopub.status.idle":"2022-10-28T20:19:53.212108Z","shell.execute_reply.started":"2022-10-28T20:19:53.202057Z","shell.execute_reply":"2022-10-28T20:19:53.211027Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text\n0  0000C359D63E  when a person has no experience on a job their...\n1  000BAD50D026  Do you think students would benefit from being...\n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.drop(['syntax',\t'vocabulary','phraseology','grammar','conventions','text_id'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.213733Z","iopub.execute_input":"2022-10-28T20:19:53.214093Z","iopub.status.idle":"2022-10-28T20:19:53.223886Z","shell.execute_reply.started":"2022-10-28T20:19:53.214057Z","shell.execute_reply":"2022-10-28T20:19:53.222860Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.225372Z","iopub.execute_input":"2022-10-28T20:19:53.225900Z","iopub.status.idle":"2022-10-28T20:19:53.247130Z","shell.execute_reply.started":"2022-10-28T20:19:53.225864Z","shell.execute_reply":"2022-10-28T20:19:53.246150Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"                                           full_text  cohesion\n0  I think that students would benefit from learn...       3.5\n1  When a problem is a change you have to let it ...       2.5\n2  Dear, Principal\\n\\nIf u change the school poli...       3.0\n3  The best time in life is when you become yours...       4.5\n4  Small act of kindness can impact in other peop...       2.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>cohesion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.cohesion.unique()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.248435Z","iopub.execute_input":"2022-10-28T20:19:53.249812Z","iopub.status.idle":"2022-10-28T20:19:53.259093Z","shell.execute_reply.started":"2022-10-28T20:19:53.249775Z","shell.execute_reply":"2022-10-28T20:19:53.257952Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"array([3.5, 2.5, 3. , 4.5, 4. , 2. , 1. , 5. , 1.5])"},"metadata":{}}]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.263661Z","iopub.execute_input":"2022-10-28T20:19:53.263968Z","iopub.status.idle":"2022-10-28T20:19:53.270967Z","shell.execute_reply.started":"2022-10-28T20:19:53.263943Z","shell.execute_reply":"2022-10-28T20:19:53.269885Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"(3911, 2)"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,6))\ntrain_df.groupby('cohesion').count().plot.bar(ylim=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.272372Z","iopub.execute_input":"2022-10-28T20:19:53.272865Z","iopub.status.idle":"2022-10-28T20:19:53.519117Z","shell.execute_reply.started":"2022-10-28T20:19:53.272831Z","shell.execute_reply":"2022-10-28T20:19:53.518119Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 576x432 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.520613Z","iopub.execute_input":"2022-10-28T20:19:53.520947Z","iopub.status.idle":"2022-10-28T20:19:53.532379Z","shell.execute_reply.started":"2022-10-28T20:19:53.520912Z","shell.execute_reply":"2022-10-28T20:19:53.531160Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                           full_text  cohesion\n0  I think that students would benefit from learn...       3.5\n1  When a problem is a change you have to let it ...       2.5\n2  Dear, Principal\\n\\nIf u change the school poli...       3.0\n3  The best time in life is when you become yours...       4.5\n4  Small act of kindness can impact in other peop...       2.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>cohesion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"MAX_LEN=256\nTRAIN_BATCH_SIZE=32\nVALID_BATCH_SIZE=32\nEPOCHS=2\nLEARNING_RATE=1e-05\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.533717Z","iopub.execute_input":"2022-10-28T20:19:53.534333Z","iopub.status.idle":"2022-10-28T20:19:53.539869Z","shell.execute_reply.started":"2022-10-28T20:19:53.534297Z","shell.execute_reply":"2022-10-28T20:19:53.538952Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer,BertModel","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.541149Z","iopub.execute_input":"2022-10-28T20:19:53.542008Z","iopub.status.idle":"2022-10-28T20:19:53.549627Z","shell.execute_reply.started":"2022-10-28T20:19:53.541965Z","shell.execute_reply":"2022-10-28T20:19:53.548899Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:53.551407Z","iopub.execute_input":"2022-10-28T20:19:53.552107Z","iopub.status.idle":"2022-10-28T20:19:55.630261Z","shell.execute_reply.started":"2022-10-28T20:19:53.552071Z","shell.execute_reply":"2022-10-28T20:19:55.629074Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"example_text=\"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\"","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.631764Z","iopub.execute_input":"2022-10-28T20:19:55.632151Z","iopub.status.idle":"2022-10-28T20:19:55.637541Z","shell.execute_reply.started":"2022-10-28T20:19:55.632108Z","shell.execute_reply":"2022-10-28T20:19:55.636429Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"encodings=tokenizer.encode_plus(\n    example_text,\n    add_special_tokens=True,\n    max_length=MAX_LEN,\n    padding='max_length',\n    truncation=True,\n    return_attention_mask=True,\n    return_tensors='pt'\n    \n    \n    )","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.639398Z","iopub.execute_input":"2022-10-28T20:19:55.640147Z","iopub.status.idle":"2022-10-28T20:19:55.649479Z","shell.execute_reply.started":"2022-10-28T20:19:55.640098Z","shell.execute_reply":"2022-10-28T20:19:55.648607Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"encodings","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.650923Z","iopub.execute_input":"2022-10-28T20:19:55.651302Z","iopub.status.idle":"2022-10-28T20:19:55.666528Z","shell.execute_reply.started":"2022-10-28T20:19:55.651267Z","shell.execute_reply":"2022-10-28T20:19:55.665476Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 101, 1045, 2228, 2008, 2493, 2052, 5770, 2013, 4083, 2012, 2188, 1010,\n         2138, 2027, 2180, 2102, 2031, 2000, 2689, 1998, 2131, 2039, 2220, 1999,\n         1996, 2851, 2000, 6457, 1998, 2079, 2045, 2606, 1012, 2635, 2069, 4280,\n         7126, 2068, 2138, 2012, 2045, 2160, 2027, 1005, 2222, 2022, 3477, 2062,\n         3086, 1012, 2027, 2097, 2022, 6625, 2012, 2188, 1012,  102,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n  def __init__(self,df,tokenizer,max_len):\n    self.df=df\n    self.tokenizer=tokenizer\n    self.max_len=max_len\n    self.title=self.df['full_text']\n    self.targets=self.df['cohesion'].values\n  def __len__(self):\n    return len(self.title)\n  def __getitem__(self,index):\n    title=str(self.title[index])\n    title=\" \".join(title.split())\n\n    inputs=self.tokenizer.encode_plus(\n        title,\n        None,\n        add_special_tokens=True,\n        max_length=self.max_len,\n        padding='max_length',\n        return_token_type_ids=True,\n        trunction=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n\n\n\n    )\n    return {\n        'input_ids':inputs['input_ids'].flatten(),\n        'attention_mask':input['attention_mask'].flatten(),\n        'token_type_ids':input['token_type_ids'].flatten(),\n        'targets':torch.FloatTensor(self.targets[index])\n    }\n\n  ","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.668737Z","iopub.execute_input":"2022-10-28T20:19:55.669588Z","iopub.status.idle":"2022-10-28T20:19:55.678080Z","shell.execute_reply.started":"2022-10-28T20:19:55.669554Z","shell.execute_reply":"2022-10-28T20:19:55.677142Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"train_size=0.8\ntrain_df=train_df.sample(frac=train_size,random_state=200).reset_index(drop=True)\nval_df=train_df.drop(train_df.index).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.679878Z","iopub.execute_input":"2022-10-28T20:19:55.680255Z","iopub.status.idle":"2022-10-28T20:19:55.694029Z","shell.execute_reply.started":"2022-10-28T20:19:55.680200Z","shell.execute_reply":"2022-10-28T20:19:55.693078Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"train_dataset=CustomDataset(train_df,tokenizer,MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.695461Z","iopub.execute_input":"2022-10-28T20:19:55.696039Z","iopub.status.idle":"2022-10-28T20:19:55.703848Z","shell.execute_reply.started":"2022-10-28T20:19:55.696001Z","shell.execute_reply":"2022-10-28T20:19:55.702891Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"val_dataset=CustomDataset(val_df,tokenizer,MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.705379Z","iopub.execute_input":"2022-10-28T20:19:55.705776Z","iopub.status.idle":"2022-10-28T20:19:55.713995Z","shell.execute_reply.started":"2022-10-28T20:19:55.705742Z","shell.execute_reply":"2022-10-28T20:19:55.713082Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"train_data_loader=torch.utils.data.DataLoader(\n    train_dataset,\n    shuffle=True,\n    batch_size=TRAIN_BATCH_SIZE,\n    num_workers=0\n)\n\n\nval_data_loader=torch.utils.data.DataLoader(\n    val_dataset,\n    shuffle=False,\n    batch_size=VALID_BATCH_SIZE,\n    num_workers=0\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.716712Z","iopub.execute_input":"2022-10-28T20:19:55.717058Z","iopub.status.idle":"2022-10-28T20:19:55.733718Z","shell.execute_reply.started":"2022-10-28T20:19:55.717022Z","shell.execute_reply":"2022-10-28T20:19:55.732643Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:19:55.736152Z","iopub.execute_input":"2022-10-28T20:19:55.736837Z","iopub.status.idle":"2022-10-28T20:19:55.744349Z","shell.execute_reply.started":"2022-10-28T20:19:55.736775Z","shell.execute_reply":"2022-10-28T20:19:55.743252Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_ckp(checkpoint_fpath, model, optimizer):\n    \"\"\"\n    checkpoint_path: path to save checkpoint\n    model: model that we want to load checkpoint parameters into       \n    optimizer: optimizer we defined in previous training\n    \"\"\"\n    # load check point\n    checkpoint = torch.load(checkpoint_fpath)\n    # initialize state_dict from checkpoint to model\n    model.load_state_dict(checkpoint['state_dict'])\n    # initialize optimizer from checkpoint to optimizer\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    # initialize valid_loss_min from checkpoint to valid_loss_min\n    valid_loss_min = checkpoint['valid_loss_min']\n    # return model, optimizer, epoch value, min validation loss \n    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n\ndef save_ckp(state, is_best, checkpoint_path, best_model_path):\n    \"\"\"\n    state: checkpoint we want to save\n    is_best: is this the best checkpoint; min validation loss\n    checkpoint_path: path to save checkpoint\n    best_model_path: path to save best model\n    \"\"\"\n    f_path = checkpoint_path\n    # save checkpoint data to the path given, checkpoint_path\n    torch.save(state, f_path)\n    # if it is a best model, min validation loss\n    if is_best:\n        best_fpath = best_model_path\n        # copy that checkpoint file to best path given, best_model_path\n        shutil.copyfile(f_path, best_fpath)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:20:18.275132Z","iopub.execute_input":"2022-10-28T20:20:18.276115Z","iopub.status.idle":"2022-10-28T20:20:18.284502Z","shell.execute_reply.started":"2022-10-28T20:20:18.276077Z","shell.execute_reply":"2022-10-28T20:20:18.283101Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 6)\n    \n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.bert_model(\n            input_ids, \n            attention_mask=attn_mask, \n            token_type_ids=token_type_ids\n        )\n        output_dropout = self.dropout(output.pooler_output)\n        output = self.linear(output_dropout)\n        return output\n\nmodel = BERTClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:20:31.088005Z","iopub.execute_input":"2022-10-28T20:20:31.088372Z","iopub.status.idle":"2022-10-28T20:20:58.990199Z","shell.execute_reply.started":"2022-10-28T20:20:31.088339Z","shell.execute_reply":"2022-10-28T20:20:58.989198Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18963c5591c4402599af84b03c775a43"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:20:58.992282Z","iopub.execute_input":"2022-10-28T20:20:58.992909Z","iopub.status.idle":"2022-10-28T20:20:58.999671Z","shell.execute_reply.started":"2022-10-28T20:20:58.992869Z","shell.execute_reply":"2022-10-28T20:20:58.998658Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"val_targets=[]\nval_outputs=[]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:20:59.001132Z","iopub.execute_input":"2022-10-28T20:20:59.001512Z","iopub.status.idle":"2022-10-28T20:20:59.010737Z","shell.execute_reply.started":"2022-10-28T20:20:59.001467Z","shell.execute_reply":"2022-10-28T20:20:59.009815Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def train_model(n_epochs, training_loader, validation_loader, model, \n                optimizer, checkpoint_path, best_model_path):\n   \n  # initialize tracker for minimum validation loss\n  valid_loss_min = np.Inf\n   \n \n  for epoch in range(1, n_epochs+1):\n    train_loss = 0\n    valid_loss = 0\n\n    model.train()\n    print('############# Epoch {}: Training Start   #############'.format(epoch))\n    for batch_idx, data in enumerate(training_loader):\n        #print('yyy epoch', batch_idx)\n        ids = data['input_ids'].to(device, dtype = torch.long)\n        mask = data['attention_mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        #if batch_idx%5000==0:\n         #   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        #print('before loss data in training', loss.item(), train_loss)\n        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n        #print('after loss data in training', loss.item(), train_loss)\n    \n    print('############# Epoch {}: Training End     #############'.format(epoch))\n    \n    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n    ######################    \n    # validate the model #\n    ######################\n \n    model.eval()\n   \n    with torch.no_grad():\n      for batch_idx, data in enumerate(validation_loader, 0):\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n\n            loss = loss_fn(outputs, targets)\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n            val_targets.extend(targets.cpu().detach().numpy().tolist())\n            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n\n      print('############# Epoch {}: Validation End     #############'.format(epoch))\n      # calculate average losses\n      #print('before cal avg train loss', train_loss)\n      train_loss = train_loss/len(training_loader)\n      valid_loss = valid_loss/len(validation_loader)\n      # print training/validation statistics \n      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n      \n      # create checkpoint variable and add important data\n      checkpoint = {\n            'epoch': epoch + 1,\n            'valid_loss_min': valid_loss,\n            'state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict()\n      }\n        \n        # save checkpoint\n      save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n        \n      ## TODO: save the model if validation loss has decreased\n      if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n        # save checkpoint as best model\n        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n        valid_loss_min = valid_loss\n\n    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:21:17.253786Z","iopub.execute_input":"2022-10-28T20:21:17.254140Z","iopub.status.idle":"2022-10-28T20:21:17.290103Z","shell.execute_reply.started":"2022-10-28T20:21:17.254107Z","shell.execute_reply":"2022-10-28T20:21:17.288898Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}